{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Example with cross validation\n\n\n...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Quentin Bertrand <quentin.bertrand@inria.fr>\n#          Quentin Klopfenstein <quentin.klopfenstein@u-bourgogne.fr>\n#\n# License: BSD (3-clause)\n\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# from sklearn.datasets import make_regression\n# from sklearn import linear_model\nfrom sklearn.linear_model import LassoCV\nfrom sparse_ho.models import Lasso\nfrom sparse_ho.criterion import CV\nfrom sparse_ho.implicit_forward import ImplicitForward\nfrom sparse_ho.utils import Monitor\nfrom sparse_ho.grad_search_CV import grad_search_CV\nfrom sparse_ho.datasets.real import load_libsvm\n\nfrom sklearn.model_selection import KFold\n\nprint(__doc__)\n\nX, y = load_libsvm('rcv1_train')\n# X, y = make_regression(\n#     n_samples=2000, n_features=1000)\n\nkf = KFold(n_splits=5, shuffle=False)\n\nfor train, test in kf.split(X):\n    print(\"%s %s\" % (train, test))\n\nprint(\"Starting path computation...\")\nn_samples = len(y)\nalpha_max = np.max(np.abs(X.T.dot(y))) / n_samples\n\nn_alphas = 10\np_alphas = np.geomspace(1, 0.0001, n_alphas)\nalphas = alpha_max * p_alphas\n\ntol = 1e-8\n\nprint('scikit started')\n\nt0 = time.time()\nreg = LassoCV(\n    cv=kf, verbose=True, tol=tol, fit_intercept=False, alphas=alphas).fit(X, y)\nreg.score(X, y)\nt_sk = time.time() - t0\n\nprint('scikit finished')\n\n\nprint('sparse-ho started')\n\nt0 = time.time()\nModel = Lasso\nCriterion = CV\nAlgo = ImplicitForward\nlog_alpha0 = np.log(alpha_max/10)\nmonitor = Monitor()\ngrad_search_CV(\n    X, y, Model, Criterion, Algo, log_alpha0, monitor, n_outer=10,\n    verbose=True, cv=kf, random_state=0, test_size=0.33,\n    tolerance_decrease='constant', tol=tol,\n    t_max=1000)\nt_grad_search = time.time() - t0\n\nprint('sparse-ho finished')\nprint(\"Time to compute CV for scikit-learn: %.2f\" % t_sk)\nprint(\"Time to compute CV for sparse-ho: %.2f\" % t_grad_search)\n\n\nobjs = reg.mse_path_.mean(axis=1)\n\np_alphas_grad = np.exp(np.array(monitor.log_alphas)) / alpha_max\nobjs_grad = np.array(monitor.objs)\n\ncurrent_palette = sns.color_palette(\"colorblind\")\n\n\nfig = plt.figure()\nplt.semilogx(\n    p_alphas, objs, color=current_palette[0], linewidth=7.0)\nplt.semilogx(\n    p_alphas, objs, 'bo', label='0-order method (grid-search)',\n    color=current_palette[1], markersize=15)\nplt.semilogx(\n    p_alphas_grad, objs_grad, 'bX', label='1-st order method',\n    color=current_palette[2], markersize=25)\nplt.xlabel(r\"$\\lambda / \\lambda_{\\max}$\", fontsize=28)\nplt.ylabel(\n    \"Cross-validation loss\",\n    fontsize=28)\naxes = plt.gca()\n# axes.set_ylim([0, 1])\nplt.tick_params(width=5)\nplt.legend(fontsize=14, loc=1)\nplt.tight_layout()\nplt.show(block=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}