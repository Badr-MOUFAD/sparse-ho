{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Grad Search CV\n\n\n...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Quentin Bertrand <quentin.bertrand@inria.fr>\n#          Quentin Klopfenstein <quentin.klopfenstein@u-bourgogne.fr>\n#\n# License: BSD (3-clause)\n\nimport time\nimport numpy as np\n# from numpy.linalg import norm\n\n# from sklearn.datasets import make_regression\n# from sklearn import linear_model\nfrom sklearn.linear_model import LassoCV\nfrom sparse_ho.models import Lasso\nfrom sparse_ho.criterion import CV\nfrom sparse_ho.implicit_forward import ImplicitForward\nfrom sparse_ho.utils import Monitor\nfrom sparse_ho.grad_search_CV import grad_search_CV\n# from sparse_ho.datasets.real import load_libsvm\nfrom sklearn.datasets import make_regression\n\nprint(__doc__)\n\n# X, y = load_libsvm('real-sim')\nX, y = make_regression(\n    n_samples=2000, n_features=1000)\n\nrandom_state = 0\ncv = 5\n\nprint(\"Starting path computation...\")\nn_samples = len(y)\nalpha_max = np.max(np.abs(X.T.dot(y))) / n_samples\n\nn_alphas = 100\nalphas = alpha_max * np.geomspace(1, 0.00001, n_alphas)\n\ntol = 1e-8\n\nprint('scikit started')\n\nt0 = time.time()\nreg = LassoCV(\n    cv=cv, random_state=random_state, verbose=True, tol=tol, fit_intercept=False, alphas=alphas).fit(X, y)\nreg.score(X, y)\nt_sk = time.time() - t0\n\nprint('scikit finished')\n\n\nprint('sparse-ho started')\n\nt0 = time.time()\nModel = Lasso\nCriterion = CV\nAlgo = ImplicitForward\nlog_alpha0 = np.log(alpha_max/10)\nmonitor = Monitor()\ngrad_search_CV(\n    X, y, Model, Criterion, Algo, log_alpha0, monitor, n_outer=100,\n    verbose=True, cv=cv, random_state=0, test_size=0.33,\n    tolerance_decrease='constant', tol=tol,\n    t_max=1000)\nt_grad_search = time.time() - t0\n\nprint('sparse-ho finished')\nprint(\"Time to compute CV for scikit-learn: %.2f\" % t_sk)\nprint(\"Time to compute CV for sparse-ho: %.2f\" % t_grad_search)\n\n# clf = linear_model.Lasso(alpha=reg.alpha_)\n# clf.fit(X, y)\n# print(\n#     norm(X @ clf.coef_ - y) ** 2 / (2 * n_samples) + reg.alpha_ * norm(\n#         clf.coef_, ord=1))\n\n# clf2 = linear_model.Lasso(alpha=np.exp(monitor.log_alphas[-1]))\n# clf2.fit(X, y)\n\n# print(\n#     norm(X @ clf2.coef_ - y) ** 2 / (2 * n_samples) + np.exp(\n#         monitor.log_alphas[-1]) * norm(clf2.coef_, ord=1))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}