{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Lasso with held-out test set\n\nThis example shows how to perform hyperparameter optimization\nfor an elastic-net using a held-out validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Quentin Bertrand <quentin.bertrand@inria.fr>\n#          Quentin Klopfenstein <quentin.klopfenstein@u-bourgogne.fr>\n#\n# License: BSD (3-clause)\n\nimport time\nimport numpy as np\nfrom sklearn import linear_model\nfrom numpy.linalg import norm\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfrom sparse_ho.datasets import get_data\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sparse_ho.implicit_forward import ImplicitForward\nfrom sparse_ho.criterion import HeldOutMSE\nfrom sparse_ho.models import ElasticNet\nfrom sparse_ho.ho import grad_search\nfrom sparse_ho.utils import Monitor\n\nAxes3D  # hack for matplotlib 3D support\n\n# dataset = \"rcv1\"\ndataset = 'simu'\n# use_small_part = False\nuse_small_part = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load some data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Started to load data\")\n\nif dataset == 'rcv1':\n    X_train, X_val, X_test, y_train, y_val, y_test = get_data(dataset)\nelse:\n    rng = np.random.RandomState(42)\n    X, y, beta = make_regression(\n        n_samples=100, n_features=300, noise=3.0, coef=True, n_informative=10,\n        random_state=rng,\n    )\n    X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n    beta /= norm(beta)\n    y = X @ beta + rng.randn(X.shape[0])\n    X_train, X_test, y_train, y_test = \\\n        train_test_split(X, y, test_size=0.33, random_state=rng)\n    X_train, X_val, y_train, y_val = train_test_split(\n        X_train, y_train, test_size=0.5, random_state=rng)\n\nprint(\"Finished loading data\")\n\nalpha_max = np.max(np.abs(X_train.T @ y_train)) / X_train.shape[0]\nlog_alpha_max = np.log(alpha_max)\n\nalpha_min = 1e-4 * alpha_max\n\nn_grid = 10\nalphas_1 = np.geomspace(0.6 * alpha_max, alpha_min, n_grid)\nlog_alphas_1 = np.log(alphas_1)\nalphas_2 = np.geomspace(0.6 * alpha_max, alpha_min, n_grid)\nlog_alphas_2 = np.log(alphas_2)\n\nresults = np.zeros((n_grid, n_grid))\ntol = 1e-4\nmax_iter = 50000\n\n\nestimator = linear_model.ElasticNet(\n    fit_intercept=False, tol=tol, max_iter=max_iter, warm_start=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid-search with scikit-learn\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Started grid-search\")\nt_grid_search = - time.time()\nfor i in range(n_grid):\n    print(\"lambda %i / %i\" % (i, n_grid))\n    for j in range(n_grid):\n        print(\"lambda %i / %i\" % (j, n_grid))\n        estimator.alpha = (alphas_1[i] + alphas_2[j])\n        estimator.l1_ratio = alphas_1[i] / (alphas_1[i] + alphas_2[j])\n        estimator.fit(X_train, y_train)\n        results[i, j] = np.mean((y_val - X_val @ estimator.coef_) ** 2)\nt_grid_search += time.time()\nprint(\"Finished grid-search\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grad-search with sparse-ho\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estimator = linear_model.ElasticNet(\n    fit_intercept=False, max_iter=max_iter, warm_start=True)\nprint(\"Started grad-search\")\nt_grad_search = - time.time()\nmonitor = Monitor()\nn_outer = 10\nmodel = ElasticNet(\n    X_train, y_train, max_iter=max_iter, estimator=estimator)\ncriterion = HeldOutMSE(\n    X_val, y_val, model, X_test=X_test, y_test=y_test)\nalgo = ImplicitForward(tol_jac=1e-7, n_iter_jac=1000, max_iter=max_iter)\n_, _, _ = grad_search(\n    algo, criterion, verbose=True,\n    log_alpha0=np.array([np.log(alpha_max * 0.3), np.log(alpha_max / 10)]),\n    tol=tol, n_outer=n_outer, monitor=monitor)\nt_grad_search += time.time()\nalphas_grad = np.exp(np.array(monitor.log_alphas))\nalphas_grad /= alpha_max\n\n\nprint(\"Time grid-search %f\" % t_grid_search)\nprint(\"Time grad-search %f\" % t_grad_search)\nprint(\"Minimum grid search %0.3e\" % results.min())\nprint(\"Minimum grad search %0.3e\" % np.array(monitor.objs).min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "idx = np.where(results == results.min())\n\na, b = np.meshgrid(alphas_1 / alpha_max, alphas_2 / alpha_max)\nfig = plt.figure()\nax = plt.axes(projection='3d')\nax.plot_surface(\n    np.log(a), np.log(b), results, rstride=1, cstride=1,\n    cmap='viridis', edgecolor='none', alpha=0.5)\nax.scatter3D(\n    np.log(a), np.log(b), results,\n    monitor.objs, c=\"black\", s=20, marker=\"o\")\nax.scatter3D(\n    np.log(alphas_grad[:, 0]), np.log(alphas_grad[:, 1]),\n    monitor.objs, c=\"red\", s=200, marker=\"X\")\nax.scatter3D(\n    np.log(alphas_2[idx[1]] / alpha_max),\n    np.log(alphas_1[idx[0]] / alpha_max),\n    [results.min()], c=\"black\", s=200, marker=\"X\")\nax.set_xlabel(\"lambda1\")\nax.set_ylabel(\"lambda2\")\nax.set_label(\"Loss on validation set\")\nfig.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}