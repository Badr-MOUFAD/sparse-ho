{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Elastic net with held-out test set\n\nThis example shows how to perform hyperparameter optimization\nfor an elastic-net using a held-out validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Quentin Bertrand <quentin.bertrand@inria.fr>\n#          Quentin Klopfenstein <quentin.klopfenstein@u-bourgogne.fr>\n#\n# License: BSD (3-clause)\n\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model\nfrom libsvmdata.datasets import fetch_libsvm\nfrom celer.datasets import make_correlated_data\nfrom sklearn.metrics import mean_squared_error\n\nfrom sparse_ho import ImplicitForward\nfrom sparse_ho.criterion import HeldOutMSE\nfrom sparse_ho.models import ElasticNet\nfrom sparse_ho.ho import grad_search\nfrom sparse_ho.utils import Monitor\nfrom sparse_ho.utils_plot import discrete_cmap\nfrom sparse_ho.optimizers import GradientDescent\n\n\n# dataset = \"rcv1\"\ndataset = 'simu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load some data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# dataset = 'rcv1'\ndataset = 'simu'\n\nif dataset == 'rcv1':\n    X, y = fetch_libsvm('rcv1.binary')\n    y -= y.mean()\n    y /= np.linalg.norm(y)\nelse:\n    X, y, _ = make_correlated_data(\n        n_samples=200, n_features=400, snr=5, random_state=0)\n\n\nn_samples = X.shape[0]\nidx_train = np.arange(0, n_samples // 2)\nidx_val = np.arange(n_samples // 2, n_samples)\n\nprint(\"Starting path computation...\")\nalpha_max = np.max(np.abs(X[idx_train, :].T @ y[idx_train])) / len(idx_train)\n\nalpha_min = 1e-4 * alpha_max\n\nn_grid = 15\nalphas_l1 = np.geomspace(alpha_max, alpha_min, n_grid)\nalphas_l2 = np.geomspace(alpha_max, alpha_min, n_grid)\n\nresults = np.zeros((n_grid, n_grid))\ntol = 1e-5\nmax_iter = 10_000\n\nestimator = linear_model.ElasticNet(\n    fit_intercept=False, tol=tol, max_iter=max_iter, warm_start=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## grid search with scikit-learn\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Started grid search\")\nt_grid_search = - time.time()\nfor i in range(n_grid):\n    print(\"lambda %i / %i\" % (i * n_grid, n_grid * n_grid))\n    for j in range(n_grid):\n        estimator.alpha = (alphas_l1[i] + alphas_l2[j])\n        estimator.l1_ratio = alphas_l1[i] / (alphas_l1[i] + alphas_l2[j])\n        estimator.fit(X[idx_train, :], y[idx_train])\n        results[i, j] = mean_squared_error(\n            y[idx_val], estimator.predict(X[idx_val, :]))\nt_grid_search += time.time()\nprint(\"Finished grid search\")\nprint(\"Minimum outer criterion value with grid search %0.3e\" % results.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grad-search with sparse-ho\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estimator = linear_model.ElasticNet(\n    fit_intercept=False, max_iter=max_iter, warm_start=True)\nprint(\"Started grad-search\")\nt_grad_search = - time.time()\nmonitor = Monitor()\nn_outer = 10\nalpha0 = np.array([alpha_max * 0.9, alpha_max * 0.9])\nmodel = ElasticNet(estimator=estimator)\ncriterion = HeldOutMSE(idx_train, idx_val)\nalgo = ImplicitForward(tol_jac=1e-3, n_iter_jac=100, max_iter=max_iter)\noptimizer = GradientDescent(\n    n_outer=n_outer, tol=tol, p_grad_norm=1.5, verbose=True)\ngrad_search(\n    algo, criterion, model, optimizer, X, y, alpha0=alpha0,\n    monitor=monitor)\nt_grad_search += time.time()\nmonitor.alphas = np.array(monitor.alphas)\n\nprint(\"Time grid search %f\" % t_grid_search)\nprint(\"Time grad-search %f\" % t_grad_search)\nprint(\"Minimum grid search %0.3e\" % results.min())\nprint(\"Minimum grad search %0.3e\" % np.array(monitor.objs).min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cmap = discrete_cmap(n_outer, 'Reds')\nX, Y = np.meshgrid(alphas_l1 / alpha_max, alphas_l2 / alpha_max)\nfig, ax = plt.subplots(1, 1)\ncp = ax.contour(X, Y, results.T, levels=40)\nax.scatter(\n    X, Y, s=10, c=\"orange\", marker=\"o\", label=\"$0$th order (grid search)\",\n    clip_on=False)\nax.scatter(\n    monitor.alphas[:, 0] / alpha_max, monitor.alphas[:, 1] / alpha_max,\n    s=40, color=cmap(np.linspace(0, 1, n_outer)), zorder=10,\n    marker=\"X\", label=\"$1$st order\")\nax.plot(\n    monitor.alphas[:, 0] / alpha_max, monitor.alphas[:, 1] / alpha_max,\n    c=cmap(0))\nax.set_xlim(X.min(), X.max())\nax.set_xlabel(\"L1 regularization\")\nax.set_ylabel(\"L2 regularization\")\nax.set_ylim(Y.min(), Y.max())\nax.set_title(\"Elastic net held out prediction loss on test set\")\ncb = fig.colorbar(cp)\ncb.set_label(\"Held-out loss\")\nplt.xscale('log')\nplt.yscale('log')\nplt.legend(loc='upper left')\nplt.show(block=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}