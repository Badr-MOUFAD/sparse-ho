{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Sparse logistic regression\n\n\nThis example shows how to perform hyperparameter optimisation\nfor sparse logistic regression using a held-out test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Quentin Bertrand <quentin.bertrand@inria.fr>\n#          Quentin Klopfenstein <quentin.klopfenstein@u-bourgogne.fr>\n#\n# License: BSD (3-clause)\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sparse_ho.ho import grad_search\nfrom sparse_ho.utils import Monitor\nfrom sparse_ho.models import SparseLogreg\nfrom sparse_ho.criterion import Logistic\nfrom sparse_ho.implicit_forward import ImplicitForward\nfrom sparse_ho.forward import Forward\nfrom sparse_ho.grid_search import grid_search\nfrom sparse_ho.datasets.real import get_rcv1\nfrom sparse_ho.datasets.real import get_real_sim\n\nprint(__doc__)\n\n# dataset = 'rcv1'\ndataset = 'simu'\n\nif dataset == 'rcv1':\n    X_train, X_val, X_test, y_train, y_val, y_test = get_rcv1()\nelse:\n    X_train, X_val, X_test, y_train, y_val, y_test = get_real_sim()\n\n\nn_samples, n_features = X_train.shape\n\nalpha_max = np.max(np.abs(X_train.T @ y_train))\nalpha_max /= 4 * n_samples\nlog_alpha_max = np.log(alpha_max)\nlog_alpha_min = np.log(alpha_max / 1000)\nmaxit = 1000\n\nlog_alpha0 = np.log(0.1 * alpha_max)\ntol = 1e-7\nuse_sk = True\n# use_sk = False\n\nn_alphas = 10\np_alphas = np.geomspace(1, 0.0001, n_alphas)\nalphas = alpha_max * p_alphas\nlog_alphas = np.log(alphas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Grid-search\n-----------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = SparseLogreg(X_train, y_train, log_alpha0, max_iter=100)\ncriterion = Logistic(X_val, y_val, model)\nalgo_grid = Forward(criterion, use_sk=use_sk)\nmonitor_grid = Monitor()\ngrid_search(\n    algo_grid, log_alpha_min, log_alpha_max, monitor_grid,\n    log_alphas=log_alphas, tol=tol)\nobjs = np.array(monitor_grid.objs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Grad-search\n-----------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = SparseLogreg(X_train, y_train, log_alpha0, max_iter=100, tol=tol)\ncriterion = Logistic(X_val, y_val, model)\nmonitor_grad = Monitor()\nalgo = ImplicitForward(criterion, tol_jac=tol, n_iter_jac=100, use_sk=use_sk)\ngrad_search(algo, log_alpha0, monitor_grad, n_outer=10, tol=tol)\nobjs_grad = np.array(monitor_grad.objs)\n\n\np_alphas_grad = np.exp(np.array(monitor_grad.log_alphas)) / alpha_max\n\nobjs_grad = np.array(monitor_grad.objs)\n\ncurrent_palette = sns.color_palette(\"colorblind\")\n\nfig = plt.figure(figsize=(5, 3))\nplt.semilogx(\n    p_alphas, objs, color=current_palette[0])\nplt.semilogx(\n    p_alphas, objs, 'bo', label='0-order method (grid-search)',\n    color=current_palette[1])\nplt.semilogx(\n    p_alphas_grad, objs_grad, 'bX', label='1-st order method',\n    color=current_palette[2])\nplt.xlabel(r\"$\\lambda / \\lambda_{\\max}$\")\nplt.ylabel(\n    r\"$ \\sum_i^n \\log \\left ( 1 + e^{-y_i^{\\rm{val}} X_i^{\\rm{val}} \"\n    r\"\\hat \\beta^{(\\lambda)} } \\right ) $\")\n\naxes = plt.gca()\naxes.set_ylim([0, 1])\nplt.tick_params(width=5)\nplt.legend(loc=1)\nplt.tight_layout()\nplt.show(block=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}