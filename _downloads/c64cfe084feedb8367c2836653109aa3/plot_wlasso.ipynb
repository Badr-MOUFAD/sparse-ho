{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Weighted Lasso with held-out test set\n\nThis example shows how to perform hyperparameter optimization\nfor a weighted Lasso using a held-out validation set.\nIn particular we compare the weighted Lasso to LassoCV on a toy example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Quentin Bertrand <quentin.bertrand@inria.fr>\n#          Quentin Klopfenstein <quentin.klopfenstein@u-bourgogne.fr>\n#          Kenan Sehic\n#          Mathurin Massias\n# License: BSD (3-clause)\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom celer import Lasso, LassoCV\nfrom celer.datasets import make_correlated_data\n\nfrom sparse_ho.models import WeightedLasso\nfrom sparse_ho.criterion import HeldOutMSE, CrossVal\nfrom sparse_ho import ImplicitForward\nfrom sparse_ho.utils import Monitor\nfrom sparse_ho.ho import grad_search\nfrom sparse_ho.optimizers import GradientDescent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset creation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, y, w_true = make_correlated_data(\n    n_samples=100, n_features=1000, random_state=0, snr=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, X_test, y, y_test = train_test_split(X, y, test_size=0.333, random_state=0)\n\nn_samples, n_features = X.shape\nidx_train = np.arange(0, n_samples // 2)\nidx_val = np.arange(n_samples // 2, n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Max penalty value\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "alpha_max = np.max(np.abs(X[idx_train, :].T @ y[idx_train])) / len(idx_train)\nn_alphas = 30\nalphas = np.geomspace(alpha_max, alpha_max / 1_000, n_alphas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create cross validation object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vanilla LassoCV\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"========== Celer's LassoCV started ===============\")\nmodel_cv = LassoCV(\n    verbose=False, fit_intercept=False, alphas=alphas, tol=1e-7, max_iter=100,\n    cv=cv, n_jobs=2).fit(X, y)\n\n# Measure mse on test\nmse_cv = mean_squared_error(y_test, model_cv.predict(X_test))\nprint(\"Vanilla LassoCV: Mean-squared error on test data %f\" % mse_cv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Weighted Lasso with sparse-ho.\nWe use the vanilla lassoCV coefficients as a starting point\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "alpha0 = model_cv.alpha_ * np.ones(n_features)\n# Weighted Lasso: Sparse-ho: 1 param per feature\nestimator = Lasso(fit_intercept=False, max_iter=100, warm_start=True)\nmodel = WeightedLasso(estimator=estimator)\nsub_criterion = HeldOutMSE(idx_train, idx_val)\ncriterion = CrossVal(sub_criterion, cv=cv)\nalgo = ImplicitForward()\nmonitor = Monitor()\noptimizer = GradientDescent(\n    n_outer=100, tol=1e-7, verbose=True, p_grad_norm=1.9)\nresults = grad_search(\n    algo, criterion, model, optimizer, X, y, alpha0, monitor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estimator.weights = monitor.alphas[-1]\nestimator.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MSE on validation set\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mse_sho_val = mean_squared_error(y, estimator.predict(X))\n\n# MSE on test set, ie unseen data\nmse_sho_test = mean_squared_error(y_test, estimator.predict(X_test))\n\n# Oracle MSE\nmse_oracle = mean_squared_error(y_test, X_test @ w_true)\n\nprint(\"Sparse-ho: Mean-squared error on validation data %f\" % mse_sho_val)\nprint(\"Sparse-ho: Mean-squared error on test (unseen) data %f\" % mse_sho_test)\n\n\nlabels = ['WeightedLasso val', 'WeightedLasso test', 'Lasso CV', 'Oracle']\n\ndf = pd.DataFrame(\n    np.array([mse_sho_val, mse_sho_test, mse_cv, mse_oracle]).reshape((1, -1)),\n    columns=labels)\ndf.plot.bar(rot=0)\nplt.xlabel(\"Estimator\")\nplt.ylabel(\"Mean squared error\")\nplt.tight_layout()\nplt.show(block=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}