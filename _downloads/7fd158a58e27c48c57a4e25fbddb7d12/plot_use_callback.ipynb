{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# How to use custom metrics?\nThis example shows how to compute customize metrics using a callback function\nas in scipy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Quentin Bertrand <quentin.bertrand@inria.fr>\n#          Quentin Klopfenstein <quentin.klopfenstein@u-bourgogne.fr>\n#\n# License: BSD (3-clause)\n\nimport numpy as np\nfrom numpy.linalg import norm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_regression\n\nfrom libsvmdata.datasets import fetch_libsvm\n\nfrom sparse_ho.models import Lasso\nfrom sparse_ho.criterion import HeldOutMSE\nfrom sparse_ho import ImplicitForward\nfrom sparse_ho.utils import Monitor\nfrom sparse_ho.ho import grad_search\n\n\nprint(__doc__)\n\n# dataset = 'rcv1'\ndataset = 'simu'\n\nif dataset == 'rcv1':\n    X, y = fetch_libsvm('rcv1_train')\nelse:\n    X, y = make_regression(\n        n_samples=1000, n_features=1000, noise=40, random_state=0)\n\n# The dataset is split in 2: the data for training and validation: X\n# Useen data X_test, asserting the quality of the model\nX, X_test, y, y_test = train_test_split(X, y, test_size=0.333, random_state=0)\n\nn_samples = X.shape[0]\nidx_train = np.arange(0, n_samples // 2)\nidx_val = np.arange(n_samples // 2, n_samples)\n\nn_samples = len(y[idx_train])\nalpha_max = np.max(np.abs(X[idx_train, :].T.dot(y[idx_train]))) / len(idx_train)\nlog_alpha0 = np.log(alpha_max / 10)\n\ntol = 1e-7\nmax_iter = 1e5\n\n\nestimator = linear_model.Lasso(\n    fit_intercept=False, max_iter=max_iter, warm_start=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Call back definition\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "objs_test = []\n\n\ndef callback(val, grad, mask, dense, log_alpha):\n    beta = np.zeros(len(mask))\n    beta[mask] = dense\n    # The custom quantity is added at each outer iteration:\n    # here the loss on test data\n    objs_test.append(\n        norm(X_test[:, mask] @ dense - y_test) ** 2 / len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grad-search with sparse-ho and callback\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('sparse-ho started')\n\nmodel = Lasso(estimator=estimator)\ncriterion = HeldOutMSE(idx_train, idx_val)\nalgo = ImplicitForward(criterion)\n# use Monitor(callback) with your custom callback\nmonitor = Monitor(callback=callback)\n\ngrad_search(\n    algo, criterion, model, X, y, np.log(alpha_max / 10), monitor,\n    n_outer=30, tol=tol)\n\n\nprint('sparse-ho finished')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "current_palette = sns.color_palette(\"colorblind\")\n\nfig = plt.figure(figsize=(5, 3))\nplt.plot(monitor.times, objs_test)\nplt.tick_params(width=5)\nplt.xlabel(\"Times (s)\")\nplt.ylabel(r\"$\\|y^{\\rm{test}} - X^{\\rm{test}} \\hat \\beta^{(\\lambda)} \\|^2$\")\nplt.legend()\nplt.tight_layout()\nplt.show(block=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}