
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_held_out_enet.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_held_out_enet.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_held_out_enet.py:


==================================
Elastic net with held-out test set
==================================

This example shows how to perform hyperparameter optimization
for an elastic-net using a held-out validation set.

.. GENERATED FROM PYTHON SOURCE LINES 10-36

.. code-block:: default


    # Authors: Quentin Bertrand <quentin.bertrand@inria.fr>
    #          Quentin Klopfenstein <quentin.klopfenstein@u-bourgogne.fr>
    #
    # License: BSD (3-clause)

    import time
    import numpy as np
    from sklearn import linear_model
    import matplotlib.pyplot as plt

    from libsvmdata.datasets import fetch_libsvm

    from sklearn.datasets import make_regression
    from sparse_ho import ImplicitForward
    from sparse_ho.criterion import HeldOutMSE
    from sparse_ho.models import ElasticNet
    from sparse_ho.ho import grad_search
    from sparse_ho.utils import Monitor
    from sparse_ho.utils_plot import discrete_cmap
    from sparse_ho.optimizers import GradientDescent


    # dataset = "rcv1"
    dataset = 'simu'








.. GENERATED FROM PYTHON SOURCE LINES 37-38

Load some data

.. GENERATED FROM PYTHON SOURCE LINES 38-76

.. code-block:: default


    print("Started to load data")
    # dataset = 'rcv1'
    dataset = 'simu'

    if dataset == 'rcv1':
        X, y = fetch_libsvm('rcv1_train')
        # X = X[:1000, :]
        y -= y.mean()
        y /= np.linalg.norm(y)
    else:
        X, y = make_regression(
            n_samples=20, n_features=100, noise=1, random_state=42)

    print("Finished loading data")

    n_samples = X.shape[0]
    idx_train = np.arange(0, n_samples // 2)
    idx_val = np.arange(n_samples // 2, n_samples)

    print("Starting path computation...")
    n_samples = len(y[idx_train])
    alpha_max = np.max(np.abs(X[idx_train, :].T.dot(y[idx_train])))
    alpha_max /= len(idx_train)

    alpha_min = 1e-4 * alpha_max

    n_grid = 10
    alphas_1 = np.geomspace(alpha_max, alpha_min, n_grid)
    alphas_2 = np.geomspace(alpha_max, alpha_min, n_grid)

    results = np.zeros((n_grid, n_grid))
    tol = 1e-5
    max_iter = 10_000

    estimator = linear_model.ElasticNet(
        fit_intercept=False, tol=tol, max_iter=max_iter, warm_start=True)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Started to load data
    Finished loading data
    Starting path computation...




.. GENERATED FROM PYTHON SOURCE LINES 77-79

Grid-search with scikit-learn
-----------------------------

.. GENERATED FROM PYTHON SOURCE LINES 79-94

.. code-block:: default


    print("Started grid-search")
    t_grid_search = - time.time()
    for i in range(n_grid):
        print("lambda %i / %i" % (i, n_grid * n_grid))
        for j in range(n_grid):
            estimator.alpha = (alphas_1[i] + alphas_2[j])
            estimator.l1_ratio = alphas_1[i] / (alphas_1[i] + alphas_2[j])
            estimator.fit(X[idx_train, :], y[idx_train])
            results[i, j] = np.mean(
                (y[idx_val] - X[idx_val, :] @ estimator.coef_) ** 2)
    t_grid_search += time.time()
    print("Finished grid-search")
    print("Minimum grid search %0.3e" % results.min())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Started grid-search
    lambda 0 / 100
    lambda 1 / 100
    lambda 2 / 100
    lambda 3 / 100
    lambda 4 / 100
    lambda 5 / 100
    lambda 6 / 100
    lambda 7 / 100
    lambda 8 / 100
    lambda 9 / 100
    Finished grid-search
    Minimum grid search 1.561e+04




.. GENERATED FROM PYTHON SOURCE LINES 95-97

Grad-search with sparse-ho
--------------------------

.. GENERATED FROM PYTHON SOURCE LINES 97-120

.. code-block:: default

    estimator = linear_model.ElasticNet(
        fit_intercept=False, max_iter=max_iter, warm_start=True)
    print("Started grad-search")
    t_grad_search = - time.time()
    monitor = Monitor()
    n_outer = 25
    log_alpha0 = np.array([np.log(alpha_max * 0.3), np.log(alpha_max / 10)])
    model = ElasticNet(max_iter=max_iter, estimator=estimator)
    criterion = HeldOutMSE(idx_train, idx_val)
    algo = ImplicitForward(tol_jac=1e-3, n_iter_jac=100, max_iter=max_iter)
    optimizer = GradientDescent(
        n_outer=n_outer, tol=tol, p_grad0=1.5, verbose=True)
    grad_search(
        algo, criterion, model, optimizer, X, y, log_alpha0=log_alpha0,
        monitor=monitor)
    t_grad_search += time.time()
    monitor.log_alphas = np.array(monitor.log_alphas)

    print("Time grid-search %f" % t_grid_search)
    print("Time grad-search %f" % t_grad_search)
    print("Minimum grid search %0.3e" % results.min())
    print("Minimum grad search %0.3e" % np.array(monitor.objs).min())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Started grad-search
    Iteration 1/25 ||Value outer criterion: 1.64e+04 ||norm grad 5.00e+02
    Iteration 2/25 ||Value outer criterion: 1.59e+04 ||norm grad 2.14e+02
    Iteration 3/25 ||Value outer criterion: 1.57e+04 ||norm grad 1.73e+02
    Iteration 4/25 ||Value outer criterion: 1.57e+04 ||norm grad 7.03e+01
    Iteration 5/25 ||Value outer criterion: 1.58e+04 ||norm grad 4.84e+02
    Iteration 6/25 ||Value outer criterion: 1.57e+04 ||norm grad 6.00e+01
    Iteration 7/25 ||Value outer criterion: 1.57e+04 ||norm grad 6.00e+01
    Iteration 8/25 ||Value outer criterion: 1.57e+04 ||norm grad 6.27e+01
    Iteration 9/25 ||Value outer criterion: 1.57e+04 ||norm grad 6.30e+01
    Iteration 10/25 ||Value outer criterion: 1.57e+04 ||norm grad 6.33e+01
    Iteration 11/25 ||Value outer criterion: 1.57e+04 ||norm grad 6.38e+01
    Iteration 12/25 ||Value outer criterion: 1.57e+04 ||norm grad 6.43e+01
    Iteration 13/25 ||Value outer criterion: 1.57e+04 ||norm grad 1.05e+02
    Iteration 14/25 ||Value outer criterion: 1.57e+04 ||norm grad 1.09e+02
    Iteration 15/25 ||Value outer criterion: 1.57e+04 ||norm grad 1.10e+02
    Iteration 16/25 ||Value outer criterion: 1.57e+04 ||norm grad 1.15e+02
    Iteration 17/25 ||Value outer criterion: 1.57e+04 ||norm grad 1.19e+02
    Iteration 18/25 ||Value outer criterion: 1.57e+04 ||norm grad 1.24e+02
    Iteration 19/25 ||Value outer criterion: 1.57e+04 ||norm grad 1.30e+02
    Iteration 20/25 ||Value outer criterion: 1.56e+04 ||norm grad 1.97e+02
    Iteration 21/25 ||Value outer criterion: 1.56e+04 ||norm grad 2.01e+02
    Iteration 22/25 ||Value outer criterion: 1.56e+04 ||norm grad 2.33e+02
    Iteration 23/25 ||Value outer criterion: 1.56e+04 ||norm grad 3.13e+02
    Iteration 24/25 ||Value outer criterion: 1.56e+04 ||norm grad 1.03e+02
    Iteration 25/25 ||Value outer criterion: 1.56e+04 ||norm grad 1.33e+02
    Time grid-search 0.081764
    Time grad-search 1.528991
    Minimum grid search 1.561e+04
    Minimum grad search 1.559e+04




.. GENERATED FROM PYTHON SOURCE LINES 121-123

Plot results
------------

.. GENERATED FROM PYTHON SOURCE LINES 123-145

.. code-block:: default


    scaling_factor = results.max()
    cmap = discrete_cmap(n_outer, 'Greens')
    c = np.linspace(1, n_outer, n_outer)
    X, Y = np.meshgrid(alphas_1 / alpha_max, alphas_2 / alpha_max)
    fig, ax = plt.subplots(1, 1)
    cp = ax.contourf(X, Y, results.T / scaling_factor)
    ax.scatter(
        X, Y, s=10, c="orange", marker="o", label="$0$ order (grid search)",
        clip_on=False, cmap="viridis")
    ax.scatter(
        np.exp(monitor.log_alphas[:, 0]) / alpha_max,
        np.exp(monitor.log_alphas[:, 1]) / alpha_max,
        s=50, cmap=cmap, c=c,
        marker="X", label="$1$st order", clip_on=False)
    ax.set_xlim(X.min(), X.max())
    ax.set_ylim(Y.min(), Y.max())
    cb = fig.colorbar(cp)
    cb.set_label("Held-out loss")
    plt.xscale('log')
    plt.yscale('log')
    plt.show(block=False)



.. image:: /auto_examples/images/sphx_glr_plot_held_out_enet_001.png
    :alt: plot held out enet
    :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  1.969 seconds)


.. _sphx_glr_download_auto_examples_plot_held_out_enet.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_held_out_enet.py <plot_held_out_enet.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_held_out_enet.ipynb <plot_held_out_enet.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
